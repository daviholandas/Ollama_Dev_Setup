#!/usr/bin/env python3
"""
VLLM Local Setup - Unified Installation & Management

Complete automated setup for running LLMs locally using VLLM with:
- Tool calling support for IDE and CLI integration
- Docker containerization with GPU acceleration
- Three specialized agents: Architect, Developer, Product Owner

Usage:
    python3 setup.py install    # Full installation
    python3 setup.py start dev  # Start developer agent
    python3 setup.py stop       # Stop all agents
    python3 setup.py status     # Check status
"""

import os
import sys
import subprocess
import json
import argparse
import time
import secrets
from pathlib import Path
from typing import Dict, List, Tuple
from dataclasses import dataclass


@dataclass
class AgentConfig:
    """Agent configuration"""
    name: str
    model: str
    port: int
    gpu_memory: float
    max_context: int
    temperature: float
    description: str


class VLLMSetup:
    """Unified VLLM Setup Manager"""

    def __init__(self):
        self.project_root = Path(__file__).parent.resolve()
        self.tools_dir = self.project_root / "tools"
        self.outputs_dir = self.project_root / "outputs"
        self.logs_dir = self.project_root / "logs"
        self.workspace_dir = self.project_root / "workspace"
        
        # Agent configurations - optimized for 16GB GPU with large context
        self.agents = {
            "architect": AgentConfig(
                name="architect",
                model="Qwen/Qwen2.5-7B-Instruct-AWQ",
                port=8003,
                gpu_memory=0.80,
                max_context=32768,  # 32k context - safe for 16GB
                temperature=0.1,
                description="Strategic system design and architecture (32k context)"
            ),
            "dev": AgentConfig(
                name="dev",
                model="Qwen/Qwen2.5-Coder-7B-Instruct-AWQ",
                port=8004,
                gpu_memory=0.85,
                max_context=32768,  # 32k context - safe for 16GB
                temperature=0.3,
                description="Code generation and implementation (32k context)"
            ),
            "po": AgentConfig(
                name="po",
                model="Qwen/Qwen2.5-7B-Instruct-AWQ",
                port=8005,
                gpu_memory=0.70,
                max_context=32768,  # 32k context - very safe
                temperature=0.5,
                description="Requirements analysis and planning (32k context)"
            ),
        }

    def log(self, message: str, level: str = "INFO") -> None:
        """Log with emoji prefix"""
        prefixes = {
            "INFO": "â„¹ï¸",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸",
            "ERROR": "âŒ",
            "RUNNING": "ðŸ”„",
        }
        print(f"{prefixes.get(level, 'â„¹ï¸')} {message}")

    def generate_api_key(self) -> str:
        """Generate a secure API key"""
        return secrets.token_urlsafe(32)

    def setup_api_key(self) -> str:
        """Setup or load API key"""
        env_file = self.project_root / ".env"
        
        # Check if .env exists with API key
        if env_file.exists():
            with open(env_file) as f:
                content = f.read()
                if "VLLM_API_KEY=" in content:
                    api_key = content.split("VLLM_API_KEY=")[1].split("\n")[0].strip()
                    if api_key and api_key != "your-secret-api-key-here":
                        self.log("âœ“ Using existing API key from .env", "SUCCESS")
                        return api_key
        
        # Generate new API key
        self.log("Generating new API key...", "RUNNING")
        api_key = self.generate_api_key()
        
        # Save to .env
        with open(env_file, "w") as f:
            f.write(f"# VLLM API Key - Generated by setup.py\n")
            f.write(f"# Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"VLLM_API_KEY={api_key}\n")
        
        self.log("âœ“ Generated and saved API key to .env", "SUCCESS")
        self.log(f"  API Key: {api_key}", "INFO")
        self.log("  ðŸ“ Save this key for your API clients", "WARNING")
        
        return api_key

    def run_command(self, cmd: List[str], check: bool = True, capture: bool = False, timeout: int = 300) -> Tuple[int, str, str]:
        """Execute shell command"""
        try:
            result = subprocess.run(
                cmd, check=check, capture_output=capture, text=True, timeout=timeout
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            self.log(f"Command timed out: {' '.join(cmd)}", "ERROR")
            return 124, "", "Timeout"
        except subprocess.CalledProcessError as e:
            return e.returncode, e.stdout or "", e.stderr or ""
        except Exception as e:
            self.log(f"Command failed: {str(e)}", "ERROR")
            return 1, "", str(e)

    def check_prerequisites(self) -> bool:
        """Check system prerequisites"""
        self.log("Checking prerequisites...", "RUNNING")
        checks = []
        
        # Check NVIDIA GPU
        code, stdout, _ = self.run_command(["nvidia-smi"], capture=True, check=False)
        if code == 0:
            self.log("âœ“ NVIDIA GPU detected", "SUCCESS")
            checks.append(True)
        else:
            self.log("âœ— NVIDIA GPU not found", "ERROR")
            checks.append(False)
        
        # Check Docker
        code, stdout, _ = self.run_command(["docker", "--version"], capture=True, check=False)
        if code == 0:
            self.log(f"âœ“ Docker: {stdout.strip()}", "SUCCESS")
            checks.append(True)
        else:
            self.log("âœ— Docker not installed", "ERROR")
            checks.append(False)
        
        # Check NVIDIA Container Toolkit
        code, _, _ = self.run_command(
            ["docker", "run", "--rm", "--gpus", "all", "nvidia/cuda:12.2.0-base-ubuntu22.04", "nvidia-smi"],
            capture=True, check=False, timeout=30
        )
        if code == 0:
            self.log("âœ“ NVIDIA Container Toolkit configured", "SUCCESS")
            checks.append(True)
        else:
            self.log("âœ— NVIDIA Container Toolkit not configured", "ERROR")
            self.log("  Install: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html", "INFO")
            checks.append(False)
        
        # Check Docker Compose
        code, _, _ = self.run_command(["docker", "compose", "version"], capture=True, check=False)
        if code == 0:
            self.log("âœ“ Docker Compose available", "SUCCESS")
            checks.append(True)
        else:
            self.log("âœ— Docker Compose not available", "ERROR")
            checks.append(False)
        
        return all(checks)

    def create_directories(self) -> None:
        """Create required directories"""
        self.log("Creating directory structure...", "RUNNING")
        dirs = [
            self.tools_dir,
            self.outputs_dir,
            self.logs_dir / "architect",
            self.logs_dir / "dev",
            self.logs_dir / "po",
            self.workspace_dir,
        ]
        for d in dirs:
            d.mkdir(parents=True, exist_ok=True)
        self.log("âœ“ Directories created", "SUCCESS")

    def create_tool_definitions(self) -> None:
        """Create tool definition files"""
        self.log("Creating tool definitions...", "RUNNING")
        
        # Common file tools
        file_tools = [
            {
                "type": "function",
                "function": {
                    "name": "read_file",
                    "description": "Read contents of a file",
                    "parameters": {
                        "type": "object",
                        "properties": {"path": {"type": "string", "description": "File path"}},
                        "required": ["path"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "write_file",
                    "description": "Write content to a file",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string", "description": "File path"},
                            "content": {"type": "string", "description": "Content to write"}
                        },
                        "required": ["path", "content"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "list_directory",
                    "description": "List directory contents",
                    "parameters": {
                        "type": "object",
                        "properties": {"path": {"type": "string", "description": "Directory path"}},
                        "required": ["path"]
                    }
                }
            },
        ]
        
        # Dev tools
        dev_tools = file_tools + [
            {
                "type": "function",
                "function": {
                    "name": "execute_code",
                    "description": "Execute Python code in sandbox",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "code": {"type": "string", "description": "Python code"},
                            "timeout": {"type": "integer", "default": 30}
                        },
                        "required": ["code"]
                    }
                }
            },
        ]
        
        # Write tool files
        tools_map = {
            "architect-tools.json": file_tools,
            "dev-tools.json": dev_tools,
            "po-tools.json": file_tools,
        }
        
        for filename, tools in tools_map.items():
            with open(self.tools_dir / filename, "w") as f:
                json.dump(tools, f, indent=2)
        
        self.log(f"âœ“ Created {len(tools_map)} tool definition files", "SUCCESS")

    def create_docker_compose(self, api_key: str) -> None:
        """Create docker-compose.yml with API key"""
        self.log("Generating docker-compose.yml...", "RUNNING")
        
        compose = {
            "version": "3.8",
            "services": {},
            "networks": {
                "default": {
                    "name": "vllm-network",
                    "driver": "bridge"
                }
            }
        }
        
        for agent_name, config in self.agents.items():
            compose["services"][f"{agent_name}-agent"] = {
                "image": "vllm/vllm-openai:latest",
                "container_name": f"vllm-{agent_name}-agent",
                "runtime": "nvidia",
                "environment": [
                    "NVIDIA_VISIBLE_DEVICES=0",
                    "CUDA_VISIBLE_DEVICES=0",
                    f"VLLM_GPU_MEMORY_UTILIZATION={config.gpu_memory}",
                    "VLLM_ENABLE_PREFIX_CACHING=1",
                    "VLLM_ENABLE_CHUNKED_PREFILL=1",
                    "VLLM_ENABLE_AUTO_TOOL_CHOICE=1",
                    "VLLM_TOOL_CALL_PARSER=hermes",
                    "VLLM_LOG_LEVEL=INFO",
                    "VLLM_ALLOW_LONG_MAX_MODEL_LEN=1",
                    f"VLLM_API_KEY={api_key}",
                ],
                "volumes": [
                    "~/.cache/huggingface:/root/.cache/huggingface",
                    "./tools:/app/tools:ro",
                    "./outputs:/outputs",
                    f"./logs/{agent_name}:/var/log/vllm",
                    "./workspace:/workspace",
                ],
                "ports": [f"{config.port}:8000"],
                "command": f"--model {config.model} --served-model-name {agent_name} --gpu-memory-utilization {config.gpu_memory} --max-model-len {config.max_context} --enable-prefix-caching --enable-auto-tool-choice --tool-call-parser hermes --api-key {api_key} --port 8000",
                "deploy": {
                    "resources": {
                        "reservations": {
                            "devices": [
                                {"driver": "nvidia", "count": 1, "capabilities": ["gpu"]}
                            ]
                        }
                    }
                },
                "healthcheck": {
                    "test": ["CMD", "curl", "-f", "http://localhost:8000/v1/models"],
                    "interval": "30s",
                    "timeout": "10s",
                    "retries": 3,
                    "start_period": "60s",
                },
                "restart": "unless-stopped",
            }
        
        import yaml
        try:
            with open(self.project_root / "docker-compose.yml", "w") as f:
                yaml.dump(compose, f, default_flow_style=False, sort_keys=False)
        except ImportError:
            # Fallback to manual YAML writing
            with open(self.project_root / "docker-compose.yml", "w") as f:
                f.write("version: '3.8'\\n\\nservices:\\n")
                for service, config_dict in compose["services"].items():
                    f.write(f"  {service}:\\n")
                    for key, value in config_dict.items():
                        if isinstance(value, list):
                            f.write(f"    {key}:\\n")
                            for item in value:
                                f.write(f"      - {item}\\n")
                        elif isinstance(value, dict):
                            f.write(f"    {key}:\\n")
                            self._write_dict(f, value, 6)
                        else:
                            f.write(f"    {key}: {value}\\n")
                f.write("\\nnetworks:\\n  default:\\n    name: vllm-network\\n    driver: bridge\\n")
        
        self.log("âœ“ docker-compose.yml created", "SUCCESS")

    def _write_dict(self, f, d, indent):
        """Helper to write nested dict"""
        for k, v in d.items():
            if isinstance(v, dict):
                f.write(f"{' ' * indent}{k}:\\n")
                self._write_dict(f, v, indent + 2)
            elif isinstance(v, list):
                f.write(f"{' ' * indent}{k}:\\n")
                for item in v:
                    if isinstance(item, dict):
                        f.write(f"{' ' * (indent + 2)}- ")
                        first = True
                        for ik, iv in item.items():
                            if not first:
                                f.write(f"{' ' * (indent + 4)}")
                            f.write(f"{ik}: {iv}\\n")
                            first = False
                    else:
                        f.write(f"{' ' * (indent + 2)}- {item}\\n")
            else:
                f.write(f"{' ' * indent}{k}: {v}\\n")

    def install(self) -> bool:
        """Full installation with API key setup"""
        print("\\n" + "="*60)
        print("ðŸš€ VLLM Local Setup - Installation")
        print("="*60 + "\\n")
        
        if not self.check_prerequisites():
            self.log("Prerequisites check failed", "ERROR")
            return False
        
        print()
        self.create_directories()
        
        # Setup API key
        api_key = self.setup_api_key()
        
        self.create_tool_definitions()
        self.create_docker_compose(api_key)
        
        print()
        self.log("Pulling VLLM Docker image...", "RUNNING")
        code, _, _ = self.run_command(
            ["docker", "pull", "vllm/vllm-openai:latest"],
            check=False, capture=True, timeout=600
        )
        
        if code == 0:
            self.log("âœ“ Docker image ready", "SUCCESS")
        else:
            self.log("Failed to pull Docker image", "WARNING")
        
        print("\\n" + "="*60)
        self.log("Installation complete!", "SUCCESS")
        print("="*60)
        print("\\nðŸ”‘ API Authentication Enabled!")
        print(f"   API Key: {api_key}")
        print("\\nðŸ“š Usage Examples:")
        print("   curl http://localhost:8001/v1/chat/completions \\")
        print(f"     -H \"Authorization: Bearer {api_key}\" \\")
        print("     -H \"Content-Type: application/json\" \\")
        print("     -d '{\"model\":\"dev\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello\"}]}'")
        print("\\nNext steps:")
        print("  1. Start agent:  python3 setup.py start dev")
        print("  2. Check status: python3 setup.py status")
        print("  3. Stop agents:  python3 setup.py stop")
        print("\\nðŸ¤– Agents (Updated with >47k context!):")
        for name, cfg in self.agents.items():
            print(f"  â€¢ {name:10} - {cfg.description}")
            print(f"    Context: {cfg.max_context:,} tokens ({cfg.max_context//1024}k)")
            print(f"    Port:    {cfg.port}")
            print()
        
        return True

    def start_agent(self, agent_name: str) -> bool:
        """Start specific agent with API key info"""
        if agent_name not in self.agents:
            self.log(f"Unknown agent: {agent_name}", "ERROR")
            return False
        
        config = self.agents[agent_name]
        self.log(f"Starting {agent_name} agent...", "RUNNING")
        self.log(f"  Model: {config.model}", "INFO")
        self.log(f"  Context: {config.max_context:,} tokens ({config.max_context//1024}k)", "INFO")
        
        # Load API key for display
        env_file = self.project_root / ".env"
        api_key = None
        if env_file.exists():
            with open(env_file) as f:
                content = f.read()
                if "VLLM_API_KEY=" in content:
                    api_key = content.split("VLLM_API_KEY=")[1].split("\n")[0].strip()
        
        # Stop others first
        self.run_command(["docker", "compose", "stop"], check=False, capture=True)
        
        # Start agent
        code, _, stderr = self.run_command(
            ["docker", "compose", "up", "-d", f"{agent_name}-agent"],
            check=False, capture=True
        )
        
        if code != 0:
            self.log(f"Failed: {stderr}", "ERROR")
            return False
        
        self.log("Waiting for agent to be ready...", "RUNNING")
        for i in range(120):
            code, _, _ = self.run_command(
                ["curl", "-sf", f"http://localhost:{config.port}/v1/models"],
                check=False, capture=True, timeout=5
            )
            if code == 0:
                self.log(f"âœ“ {agent_name.upper()} ready at http://localhost:{config.port}", "SUCCESS")
                if api_key:
                    self.log(f"ðŸ”‘ API Key: {api_key}", "INFO")
                    self.log(f"   Use: curl -H \"Authorization: Bearer {api_key}\" http://localhost:{config.port}/v1/chat/completions", "INFO")
                return True
            if i % 10 == 0:
                print(".", end="", flush=True)
            time.sleep(1)
        
        self.log("Failed to start (timeout)", "ERROR")
        return False

    def stop_all(self) -> None:
        """Stop all agents"""
        self.log("Stopping all agents...", "RUNNING")
        self.run_command(["docker", "compose", "down"], check=False, capture=True)
        self.log("âœ“ All agents stopped", "SUCCESS")

    def show_status(self) -> None:
        """Show agent status"""
        self.log("Agent Status:", "INFO")
        print()
        code, stdout, _ = self.run_command(
            ["docker", "compose", "ps", "--format", "json"],
            check=False, capture=True
        )
        
        if code != 0 or not stdout.strip():
            self.log("No agents running", "WARNING")
            return
        
        try:
            containers = [json.loads(line) for line in stdout.strip().split("\\n")]
            for c in containers:
                name = c.get("Service", "unknown")
                state = c.get("State", "unknown")
                if state == "running":
                    agent = name.replace("-agent", "")
                    port = self.agents[agent].port if agent in self.agents else "?"
                    self.log(f"  {name:20} | Running | http://localhost:{port}", "SUCCESS")
                else:
                    self.log(f"  {name:20} | {state}", "WARNING")
        except Exception as e:
            self.log(f"Error: {e}", "ERROR")

    def list_agents(self) -> None:
        """List available agents"""
        print("\\nðŸ¤– Available Agents:\\n")
        for name, cfg in self.agents.items():
            print(f"  {name.upper()}")
            print(f"    Model:       {cfg.model}")
            print(f"    Port:        {cfg.port}")
            print(f"    Context:     {cfg.max_context} tokens")
            print(f"    Description: {cfg.description}")
            print()


def main():
    parser = argparse.ArgumentParser(
        description="VLLM Local Setup - Unified Management",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 setup.py install         # Full installation
  python3 setup.py start dev       # Start developer agent
  python3 setup.py stop            # Stop all agents
  python3 setup.py status          # Check status
  python3 setup.py list            # List agents
        """
    )
    
    parser.add_argument("action", choices=["install", "start", "stop", "status", "list"], help="Action to perform")
    parser.add_argument("agent", nargs="?", choices=["architect", "dev", "po"], help="Agent name (for start)")
    
    args = parser.parse_args()
    setup = VLLMSetup()
    
    try:
        if args.action == "install":
            sys.exit(0 if setup.install() else 1)
        elif args.action == "start":
            if not args.agent:
                print("Error: specify agent (architect, dev, po)")
                sys.exit(1)
            sys.exit(0 if setup.start_agent(args.agent) else 1)
        elif args.action == "stop":
            setup.stop_all()
        elif args.action == "status":
            setup.show_status()
        elif args.action == "list":
            setup.list_agents()
    except KeyboardInterrupt:
        print("\\n\\nInterrupted")
        sys.exit(130)
    except Exception as e:
        setup.log(f"Error: {e}", "ERROR")
        sys.exit(1)


if __name__ == "__main__":
    main()
